// Copyright 2023 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

namespace runtime {
extern runtime TierUpWasmToJSWrapper(NoContext, WasmApiFunctionRef): JSAny;
}  // namespace runtime

namespace wasm {
@export
struct WasmToJSResult {
  popCount: intptr;
  result0: intptr;
  result1: intptr;
  result2: float64;
  result3: float64;
}

extern builtin CallVarargs(
    Context,
    JSAny,      // target
    int32,      // number of arguments already on the stack
    int32,      // number of arguments in the FixedArray
    FixedArray  // arguments list
    ): JSAny;

extern builtin IterableToFixedArrayForWasm(Context, JSAny, Smi): FixedArray;

@export
transitioning macro WasmToJSWrapper(ref: WasmApiFunctionRef): WasmToJSResult {
  // Spill the signature on the stack so that it can be read by the GC. This is
  // done in the very beginning before a GC could be triggered.
  // Caller FP + return address.
  const sigSlot = LoadFramePointer() + 2 * torque_internal::SizeOf<intptr>();
  *GetRefAt<intptr>(sigSlot, 0) = BitcastTaggedToWord(ref.sig);

  ModifyWasmToJSCounter(1);
  ModifyThreadInWasmFlag(0);
  // Trigger a wrapper tier-up when this function got called often enough.
  dcheck(ref.wrapper_budget > 0);
  ref.wrapper_budget = ref.wrapper_budget - 1;
  if (ref.wrapper_budget == 0) {
    runtime::TierUpWasmToJSWrapper(kNoContext, ref);
  }

  const signaturePod = &ref.sig.bytes;
  const serializedSig = torque_internal::unsafe::NewConstSlice<int32>(
      signaturePod.object, signaturePod.offset,
      signaturePod.length / torque_internal::SizeOf<int32>());
  const returnCount =
      Convert<intptr>(*torque_internal::unsafe::NewReference<int32>(
          serializedSig.object, serializedSig.offset));
  const paramCount: intptr = serializedSig.length - returnCount - 1;
  const returnTypes = Subslice(serializedSig, Convert<intptr>(1), returnCount)
      otherwise unreachable;
  const paramTypes = Subslice(serializedSig, returnCount + 1, paramCount)
      otherwise unreachable;

  const outParams = WasmAllocateFixedArray(paramCount + 1);
  let nextIndex: intptr = 0;
  // Set the receiver to `Undefined` as the default. If the receiver would be
  // different, e.g. the global proxy for sloppy functions, then the CallVarargs
  // builtin takes care of it automatically
  outParams.objects[nextIndex++] = Undefined;

  // Caller FP + return address + signature.
  const stackParamStart =
      LoadFramePointer() + 3 * torque_internal::SizeOf<intptr>();
  const inParams = torque_internal::unsafe::NewOffHeapReference(
      %RawDownCast<RawPtr<intptr>>(stackParamStart));

  let locationAllocator = LocationAllocatorForParams(inParams);

  let paramIt = paramTypes.Iterator();

  let hasTaggedParams: bool = false;
  while (!paramIt.Empty()) {
    const paramType = paramIt.NextNotEmpty();
    if (paramType == kWasmI32Type) {
      const slot = locationAllocator.GetGPSlot();
      const val = *RefCast<int32>(slot);
      outParams.objects[nextIndex++] = Convert<Number>(val);
    } else if (paramType == kWasmF32Type) {
      const slot = locationAllocator.GetFP32Slot();
      const val = *RefCast<float32>(slot);
      outParams.objects[nextIndex++] = Convert<Number>(val);
    } else if (paramType == kWasmI64Type) {
      if constexpr (Is64()) {
        const slot = locationAllocator.GetGPSlot();
        const val = *slot;
        outParams.objects[nextIndex++] = I64ToBigInt(val);
      } else {
        const lowWordSlot = locationAllocator.GetGPSlot();
        const highWordSlot = locationAllocator.GetGPSlot();
        const lowWord = *lowWordSlot;
        const highWord = *highWordSlot;
        outParams.objects[nextIndex++] = I32PairToBigInt(lowWord, highWord);
      }
    } else if (paramType == kWasmF64Type) {
      const slot = locationAllocator.GetFP64Slot();
      const val = *RefCast<float64>(slot);
      outParams.objects[nextIndex++] = Convert<Number>(val);
    } else {
      nextIndex++;
      hasTaggedParams = true;
    }
  }

  // Second loop for tagged parameters.
  if (hasTaggedParams) {
    nextIndex = 1;
    paramIt = paramTypes.Iterator();
    while (!paramIt.Empty()) {
      const paramType = paramIt.NextNotEmpty();
      const paramKind = paramType & kValueTypeKindBitsMask;
      if (paramKind == ValueKind::kRef || paramKind == ValueKind::kRefNull) {
        const slot = locationAllocator.GetGPSlot();
        const rawRef = *slot;
        const value = BitcastWordToTagged(rawRef);
        outParams.objects[nextIndex] =
            WasmToJSObject(ref.native_context, value, paramType);
      }
      nextIndex++;
    }
  }
  const target = ref.callable;

  const context = ref.native_context;

  const result = CallVarargs(
      context, target, 0, Convert<int32>(paramCount) + 1, outParams);

  let resultFixedArray: FixedArray;
  if (returnCount > 1) {
    resultFixedArray =
        IterableToFixedArrayForWasm(context, result, Convert<Smi>(returnCount));
  } else {
    resultFixedArray = kEmptyFixedArray;
  }

  const gpRegSlots = %RawDownCast<RawPtr<intptr>>(StackSlotPtr(
      2 * torque_internal::SizeOf<intptr>(),
      torque_internal::SizeOf<intptr>()));
  const fpRegSlots = %RawDownCast<RawPtr<float64>>(StackSlotPtr(
      2 * torque_internal::SizeOf<float64>(),
      torque_internal::SizeOf<float64>()));
  // The return area on the stack starts right after the stack area.
  const stackSlots = locationAllocator.GetStackEnd();
  locationAllocator =
      LocationAllocatorForReturns(gpRegSlots, fpRegSlots, stackSlots);

  let returnIt = returnTypes.Iterator();
  nextIndex = 0;
  while (!returnIt.Empty()) {
    let retVal: JSAny;
    if (returnCount == 1) {
      retVal = result;
    } else {
      retVal = UnsafeCast<JSAny>(resultFixedArray.objects[nextIndex++]);
    }
    const retType = returnIt.NextNotEmpty();
    if (retType == kWasmI32Type) {
      let toRef = locationAllocator.GetGPSlot();
      typeswitch (retVal) {
        case (smiVal: Smi): {
          *toRef = Convert<intptr>(Unsigned(SmiToInt32(smiVal)));
        }
        case (heapVal: JSAnyNotSmi): {
          *toRef = Convert<intptr>(Unsigned(WasmTaggedNonSmiToInt32(heapVal)));
        }
      }
    } else if (retType == kWasmF32Type) {
      let toRef = locationAllocator.GetFP32Slot();
      *toRef = Convert<intptr>(Bitcast<uint32>(WasmTaggedToFloat32(retVal)));
    } else if (retType == kWasmF64Type) {
      let toRef = locationAllocator.GetFP64Slot();
      *RefCast<float64>(toRef) = ChangeTaggedToFloat64(retVal);
    } else if (retType == kWasmI64Type) {
      if constexpr (Is64()) {
        let toRef = locationAllocator.GetGPSlot();
        const v = TruncateBigIntToI64(context, retVal);
        *toRef = v;
      } else {
        let toLowRef = locationAllocator.GetGPSlot();
        let toHighRef = locationAllocator.GetGPSlot();
        const bigIntVal = ToBigInt(context, retVal);
        const pair = BigIntToRawBytes(bigIntVal);
        *toLowRef = Signed(pair.low);
        *toHighRef = Signed(pair.high);
      }
    } else {
      // Not implemented yet.
      unreachable;
    }
  }

  const popCount =
      (Convert<intptr>(stackSlots) - Convert<intptr>(stackParamStart)) /
          torque_internal::SizeOf<intptr>() +
      // The additional slot for the signature.
      1;

  ModifyThreadInWasmFlag(1);
  ModifyWasmToJSCounter(-1);
  return WasmToJSResult{
    popCount: popCount,
    result0: *GetRefAt<intptr>(gpRegSlots, 0),
    result1: *GetRefAt<intptr>(gpRegSlots, torque_internal::SizeOf<intptr>()),
    result2: *GetRefAt<float64>(fpRegSlots, 0),
    result3: *GetRefAt<float64>(fpRegSlots, torque_internal::SizeOf<float64>())
  };
}
}  // namespace wasm
